<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/component---src-templates-articletemplate-js.b269fc125bd98eed048b.css">@import url(https://fonts.googleapis.com/css?family=Lora);body{overflow-x:hidden;position:relative}.navbar{color:#fff;position:absolute;right:5vw;top:5vh;z-index:1000}.bar2,.bar3,.navbar .bar1{background-color:hsla(0,0%,100%,.5);height:4px;margin:6px 0;transition:.4s;width:35px}.navbar-active .bar1,.navbar:hover .bar1,.navbar:hover .bar2,.navbar:hover .bar3{background-color:#fff}.navbar-active .bar1{-webkit-transform:rotate(-45deg) translate(-9px,6px);transform:rotate(-45deg) translate(-9px,6px)}.navbar-active .bar2{opacity:0}.navbar-active .bar3{-webkit-transform:rotate(45deg) translate(-8px,-6px);background-color:#fff;transform:rotate(45deg) translate(-8px,-6px)}.navmenu{background-color:rgba(0,0,0,.8);min-height:100%;padding-top:15vh;position:absolute;right:0;top:0;transition:.4s;width:100%;z-index:500}.navmenu .navmenu-item{border-bottom-style:solid;border-bottom-width:2px;margin-left:3vw;margin-right:3vw;padding:20px}.navmenu .navmenu-item a{color:#fff;text-decoration:none}.coverImage{background-color:#000;background-position:50%;background-repeat:no-repeat;background-size:cover;height:100vh;left:0;position:fixed;top:0;transition:background-image 2s ease-in-out;width:100vw}.coverArrow{bottom:10vh;color:hsla(0,0%,100%,.5);font-size:6vh;max-height:60px;position:fixed;right:10vw;text-decoration:none;transition:color .5s ease-in-out}@media screen and (orientation:landscape){.coverArrow{font-size:6vw}}.coverArrow:hover{color:#fff;transition:color .5s ease-in-out}.gridPage{background-color:#000;color:#fff;height:100%;min-height:100vh;overflow-x:hidden;padding-top:10vh;width:100vw}.pageCard{background-color:#fff;background-position:50%;background-repeat:no-repeat;background-size:cover;border-style:groove;border-width:medium;color:#000;display:block;margin-bottom:5vh;margin-left:10vw;margin-right:10vw;min-height:30vh;opacity:.75;position:relative;text-align:right;text-decoration:none;width:80vw}.pageCard:hover{opacity:1;transition:.4s}.pageCard .pageCardContent{bottom:0;line-height:0;margin:20px;max-height:100%;position:absolute;right:0}.pageCard .pageCardContent .p{text-overflow:clip}.articlePage{height:100vh}.articleHeader{height:200px;max-height:50vh;padding-top:5vh;position:relative}.articleHeader h1{bottom:0;left:5vw;position:absolute}.articleBody{padding-left:5vw;padding-right:5vw;padding-top:5vh}@media (min-width:768px){.navmenu{max-width:450px}.pageCard{display:inline-block;margin-left:7vw;margin-right:0;min-height:20vh;width:40vw}}</style><meta name="generator" content="Gatsby 2.0.2"/><title data-react-helmet="true"></title><link rel="shortcut icon" href="/icons/icon-48x48.png"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="theme-color" content="#663399"/><link as="script" rel="preload" href="/component---src-templates-articletemplate-js-aaa78070bb8c763d8b1d.js"/><link as="script" rel="preload" href="/app-91e3f630fd20a5e5c29f.js"/><link as="script" rel="preload" href="/webpack-runtime-e4a7fdcba06b2e701637.js"/><link rel="preload" href="/static/d/375/path---research-conference-4-abc-311-ttpm5SvHnk6KU7V5RQt7S1OMIJs.json" as="fetch" crossOrigin="use-credentials"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" role="group"><div class="articlePage"><div class="articleHeader" style="background-color:rgb(150,66,33);color:white"><h1>Running Gaussian reference-based reconstruction for video compressed sensing</h1></div><div class="articleBody"><div><p><strong>Authors</strong>: W. Hotrakool, C. Abhayaratne</p>
<p><strong>Appeared in</strong>: Proceedings of 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</p>
<p><strong>Year</strong>: 2014</p>
<p><strong>Abstract</strong>: Our recent work has shown that quality of compressed sensing reconstruction can be improved immensely by minimising the error between the signal and a correlated reference, as opposed to the conventional l1-minimisation of the data measurements. This paper introduces a method for online estimating suitable references for video sequences using the running Gaussian average. The proposed method can provide robustness to video content changes as well as reconstruction noise. The experimental results demonstrate the performance of this method to be superior to those of the state-of-the-art l1-min methods. The results are comparable to the lossless reference reconstruction approach.</p>
<p><strong>DOI</strong>: <a href="http://dx.doi.org/10.1109/ICASSP.2014.6853949">10.1109/ICASSP.2014.6853949</a></p>
<p><strong>Find it on</strong>: <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&#x26;arnumber=6853949">IEEEXplore</a>, <a href="https://www.researchgate.net/publication/264121729_Running_Gaussian_reference-based_reconstruction_for_video_compressed_sensing">ResearchGate</a></p>
<p><strong>Copy BiBTeX</strong>:</p>
<pre><code>@inproceedings{6853949,
author={Hotrakool, Wattanit and Abhayaratne, Charith},
booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Running Gaussian reference-based reconstruction for video compressed sensing},
year={2014},
month={May},
pages={2001-2005}}
</code></pre></div></div><div><div class="navbar"><div class="bar1"></div><div class="bar2"></div><div class="bar3"></div></div><div class="navmenu" style="right:-100%"><div class="navmenu-item"><a href="/">Main</a></div><div class="navmenu-item"><a href="/research/">Research</a></div><div class="navmenu-item"><a href="/development/">Development</a></div><div class="navmenu-item"><a href="/business/">Business</a></div><div class="navmenu-item"><a href="/hobbies/">Hobbies</a></div><div class="navmenu-item"><a href="/blog/">Blog</a></div><div class="navmenu-item"><a href="/contacts/">Contacts</a></div></div></div></div></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.page={"componentChunkName":"component---src-templates-articletemplate-js","jsonName":"research-conference-4-abc","path":"/research/conference-4/"};window.dataPath="375/path---research-conference-4-abc-311-ttpm5SvHnk6KU7V5RQt7S1OMIJs";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-91e3f630fd20a5e5c29f.js"],"component---node-modules-gatsby-plugin-offline-app-shell-js":["/component---node-modules-gatsby-plugin-offline-app-shell-js-8b39cf320710777c95f1.js"],"component---src-templates-articletemplate-js":["/component---src-templates-articletemplate-js.b269fc125bd98eed048b.css","/component---src-templates-articletemplate-js-aaa78070bb8c763d8b1d.js"],"component---src-pages-404-js":["/component---src-pages-404-js.4a8f95496b390a9daea2.css","/component---src-pages-404-js-92c5aa08eabadc4437fd.js"],"component---src-pages-blog-js":["/component---src-pages-blog-js.b269fc125bd98eed048b.css","/component---src-pages-blog-js-b7af14a161b822b47dd7.js"],"component---src-pages-hobbies-js":["/component---src-pages-hobbies-js.b269fc125bd98eed048b.css","/component---src-pages-hobbies-js-a00f1267f98eb2299649.js"],"component---src-pages-index-js":["/component---src-pages-index-js.b269fc125bd98eed048b.css","/component---src-pages-index-js-d37f01ca76e009424dcf.js"],"component---src-pages-mainmenu-js":["/component---src-pages-mainmenu-js.b269fc125bd98eed048b.css","/component---src-pages-mainmenu-js-f6c2a2b9dbf82d8db857.js"],"component---src-pages-page-2-js":["/component---src-pages-page-2-js.4a8f95496b390a9daea2.css","/component---src-pages-page-2-js-de0705e0064c5371edba.js"]};/*]]>*/</script><script src="/webpack-runtime-e4a7fdcba06b2e701637.js" async=""></script><script src="/app-91e3f630fd20a5e5c29f.js" async=""></script><script src="/component---src-templates-articletemplate-js-aaa78070bb8c763d8b1d.js" async=""></script></body></html>